# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mVLr7AM1dwoGIk4TUWnhkT7ggFcoTrN0

**[Milestone 1](https://)**

**Project Name : Agriculture Crop Yield**

**The dataset**
"""

df = pd.read_csv('crop_yield.csv')
df

"""**At least 10 columns with varying data types**

**At least 100 rows (data points).**
"""

display(df.head(100))

df.info()

df.sample(10)

df.describe()

df.sample(10)

"""**[Milestone 2](https://)**

**Sampling Assignment**

**Implementing Probability Sampling Methods in Python**

Instructions

Upload your dataset (minimum 200 rows), then complete all parts A–F.

**Part A — Setup**
**Report dataset size (rows, columns)**
"""

import pandas as pd
import numpy as np


df = pd.read_csv('/content/crop_yield.csv')
df.head(10)

print("Dataset size:", df.shape)
population_mean = df['Temperature_Celsius'].mean()

"""**Part B — Simple Random Sampling (20 points)**"""

import pandas as pd
import numpy as np

df = pd.read_csv('/content/crop_yield.csv')
df.head(50)

sample_df = df.sample(n=50, random_state=42)
sample_mean = sample_df['Temperature_Celsius'].mean()


print(f"Population Mean (Temperature_Celsius): {population_mean:.2f}")
print(f"Sample Mean (Temperature_Celsius, n=50): {sample_mean:.2f}")

"""
**Part B — Simple Random Sampling**
"""

sample_size = 50
srs = df.sample(n=sample_size, random_state=42)
display(srs.head())
population_mean = df['Temperature_Celsius'].mean()
print("Population mean:", population_mean)
srs_mean = srs['Temperature_Celsius'].mean()
print("Sample mean:", srs_mean)

"""**Part C — Systematic Sampling**"""

n = 50
k = len(df) // n
start = np.random.randint(0, k)
sys_sample = df.iloc[start::k][:n]
display(sys_sample.head())
sys_mean = sys_sample['Temperature_Celsius'].mean()
print ("\n")
print("Sample mean:", sys_mean)

"""**Part D — Stratified Sampling**"""

strata_col = "Region"  # Corrected to an existing column
sample_size = 50

# proportional fraction for each group
frac = sample_size / len(df)

# stratified sample
stratified_sample = df.groupby(strata_col, group_keys=False).sample(frac=frac, random_state=42)

display(stratified_sample.head())
strat_mean = stratified_sample['Temperature_Celsius'].mean() # Corrected column name

print ("\n")
print("Sample mean:", strat_mean)

"""**Part E — Cluster Sampling**"""

df['cluster_id'] = df.index // (len(df)//10)  # 10 clusters
selected_clusters = np.random.choice(df['cluster_id'].unique(), size=2, replace=False)
cluster_sample = df[df['cluster_id'].isin(selected_clusters)]
print("Selected clusters:", selected_clusters)
display(cluster_sample.head())
cluster_mean = cluster_sample['Temperature_Celsius'].mean() # Corrected column name

print ("\n")
print("Sample mean:", cluster_mean)

"""
**Part F — Comparison & Reflection**


Compare sample means vs population mean, then write your reflection."""

df['cluster_id'] = df.index // (len(df)//10)  # 10 clusters
selected_clusters = np.random.choice(df['cluster_id'].unique(), size=2, replace=False)
cluster_sample = df[df['cluster_id'].isin(selected_clusters)]
print("Selected clusters:", selected_clusters)
cluster_sample.head()

comparison = pd.DataFrame({
    'Method': ['Simple Random', 'Systematic', 'Stratified', 'Cluster'],
    'Sample Mean': [srs_mean, sys_mean, strat_mean, cluster_mean],
    'Population Mean': [population_mean]*4,
    'Difference': [(srs_mean - population_mean),
                   (sys_mean - population_mean),
                   (strat_mean - population_mean),
                   (cluster_mean - population_mean)]
})
print(comparison)

"""**Part F — Comparison & Reflection**"""

print ("Compare sample means vs population mean, then write your reflection.")

print ("In this milestone, I applied four probability sampling methods to the\nAgricultureCrop Yield dataset from Kaggle, which includes crop production\ndata across multiple countries.\nThe goal was to compare Simple Random Sampling, Systematic Sampling,\nStratified Sampling and Cluster Sampling in estimating the population mean of\ncrop yield, which was 32.337344 t/ha.\nStratified sampling produced the most accurate result with a mean of 32.3276\nt/ha, as proportional allocation preserved the distribution of crop types and\nregions.\nSimple Random Sampling yielded 32.25 t/ha, slightly lower, while systematic\nsampling gave 32.3872 t/ha, slightly higher.\nCluster sampling showed the largest deviation at 32.5075 t/ha due to\npotential homogeneity within clusters.\nIn terms of implementation, Simple Random Sampling was easiest, requiring\nminimal code.\nSystematic sampling was straightforward with a defined step size, while\nstratified sampling needed careful grouping.\nCluster sampling was simple but required thoughtful cluster selection.")

print("Overall, stratified sampling ensured maximum accuracy, and Simple Random\nSam- pling was the simplest to implement.")

"""[**Milestone 3**](https://)


**Frequency Distribution and Data Visualization**

**Part 1: Data Loading and Preparation**


In this section, we will load the dataset and import the necessary libraries for our analysis.

Note: Remove the HASHTAG in the next cell to allow installation of the packages required [IF NEEDED]
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Dataset
file_path = '/content/crop_yield.csv'
df = pd.read_csv(file_path)

# Dataset
print("Dataset Shape:", df.shape)
print("\nColumns in Dataset:\n", df.columns)
print("\nFirst 5 Rows:\n", df.head())
print("\nMissing Values:\n", df.isnull().sum())

import pandas as pd
import numpy as np

df = pd.read_csv('/content/crop_yield.csv')

df.head()

"""**Part 2: Frequency Distribution Table**

Here, we will select a column and construct a frequency distribution table.
"""

import pandas as pd
import numpy as np


df = pd.read_csv('/content/crop_yield.csv')


column_to_analyze = 'Crop'



freq_table = pd.DataFrame(df[column_to_analyze].value_counts()).reset_index()
freq_table.columns = ['Class/Category', 'Frequency (f)']
freq_table = freq_table.sort_values(by='Class/Category').reset_index(drop=True)


total_count = freq_table['Frequency (f)'].sum()
freq_table['Relative Frequency (rf)'] = freq_table['Frequency (f)'] / total_count


freq_table['Cumulative Frequency (cf)'] = freq_table['Frequency (f)'].cumsum()


freq_table['Relative Cumulative Frequency (rcf)'] = freq_table['Relative Frequency (rf)'].cumsum()

print(" Frequency Distribution Table for:", column_to_analyze)
freq_table

column_to_analyze = 'column_name'

column_to_analyze = 'Yield_tons_per_hectare'
freq_table = pd.DataFrame(df[column_to_analyze].value_counts()).reset_index()
freq_table.columns = ['Class/Category', 'Frequency (f)']
freq_table = freq_table.sort_values(by='Class/Category').reset_index(drop=True)


total_count = freq_table['Frequency (f)'].sum()
freq_table['Relative Frequency (rf)'] = freq_table['Frequency (f)'] / total_count

freq_table['Cumulative Frequency (cf)'] = freq_table['Frequency (f)'].cumsum()


freq_table['Relative Cumulative Frequency (rcf)'] = freq_table['Relative Frequency (rf)'].cumsum()



print("Frequency Distribution Table for '" + column_to_analyze + "'")
freq_table

"""**Part 3: Graphical Representation**


In this section, we will visualize the data distribution using various charts.
"""

df.sample(10)

"""**Bar Chat**"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

df = pd.read_csv('/content/crop_yield.csv')

sample_20_df = df.sample(n=10, random_state=20)
print("First 5 rows of the 20-row sample:")
display(sample_20_df.head())


crop_counts_sample = sample_20_df['Crop'].value_counts().reset_index()
crop_counts_sample.columns = ['Crop Type', 'Frequency']


plt.figure(figsize=(10, 6))
sns.barplot(x='Crop Type', y='Frequency', data=crop_counts_sample, palette='viridis', hue='Crop Type', legend=False)
plt.title('Bar Chat of Yield Frequency Distribution of Crop Types (20-Row Sample)')
plt.xlabel('Crop Type')
plt.ylabel('Frequency')
plt.xticks(rotation=40, ha='right')
plt.grid(axis='y', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd # Ensure pandas is imported

df = pd.read_csv('/content/crop_yield.csv') # Reload the original DataFrame

sample_30_df = df.sample(n=30, random_state=20)
print("First 5 rows of the 30-row sample:")
display(sample_30_df.head())


plt.figure(figsize=(10, 6))
sns.histplot(sample_30_df['Yield_tons_per_hectare'], kde=True, bins=5, color='skyblue')
plt.title('Histogram of Yield (tons per hectare) (30-Row Sample)')
plt.xlabel('Yield (tons per hectare)')
plt.ylabel('Frequency')
plt.grid(axis='y', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd

df = pd.read_csv('/content/crop_yield.csv')
sample_30_df = df.sample(n=30, random_state=20)
print("First 5 rows of the 30-row sample:")
display(sample_30_df.head())


plt.figure(figsize=(10, 6))
sns.ecdfplot(data=sample_30_df, x='Yield_tons_per_hectare', color='skyblue')
plt.title('Ogive Chart (Cumulative Frequency) of Yield (tons per hectare) (30-Row Sample)')
plt.xlabel('Yield (tons per hectare)')
plt.ylabel('Cumulative Frequency / Proportion')
plt.grid(axis='both', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np



hist, bin_edges = np.histogram(sample_30_df['Yield_tons_per_hectare'], bins=5)


bin_midpoints = (bin_edges[:-1] + bin_edges[1:]) / 2


plt.figure(figsize=(10, 6))
plt.plot(bin_midpoints, hist, marker='o', linestyle='-', color='purple')
plt.title('Frequency Polygon of Yield (tons per hectare) (30-Row Sample)')
plt.xlabel('Yield (tons per hectare)')
plt.ylabel('Frequency')
plt.grid(axis='y', alpha=0.7)
plt.tight_layout()
plt.show()

"""**Rainfall**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


rainfall_data = {
    'Rainfall_mm': [347.733856, 191.661333, 985.486244, 230.494966, 944.241902],
    'Region': ['South', 'North', 'East', 'West', 'North'],
    'Crop': ['Maize', 'Wheat', 'Rice', 'Rice', 'Barley']
}

df = pd.DataFrame(rainfall_data)

print("Rainfall Table:")
print("=" * 45)
print(df[['Rainfall_mm', 'Region', 'Crop']].to_string(index=False))
print("=" * 45)


# Ensure df_full is loaded (assuming it should be the crop_yield.csv dataset)
df_full = pd.read_csv('/content/crop_yield.csv')

# Data to be plotted is Rainfall_mm from the full dataset
temp_data = df_full['Rainfall_mm'] # Renamed from temp_data to avoid confusion with actual temperature

plt.figure(figsize=(12, 8))


plt.subplot(2, 2, 1) # Standardized to 2x2 grid
plt.hist(temp_data, bins=20, color='lightblue', edgecolor='black')
plt.title('1. Histogram (Rainfall)')
plt.xlabel('Rainfall (mm)') # Corrected label
plt.ylabel('Frequency')

plt.subplot(2, 2, 2) # Standardized to 2x2 grid
sorted_data = np.sort(temp_data)
cumulative = np.arange(1, len(sorted_data) + 1)
plt.plot(sorted_data, cumulative, 'r-')
plt.title('2. Ogive Chart (Rainfall)')
plt.xlabel('Rainfall (mm)') # Corrected label
plt.ylabel('Cumulative Frequency')


plt.subplot(2, 2, 3) # Standardized to 2x2 grid (moved to next position)
counts, bin_edges = np.histogram(temp_data, bins=20)
bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2
plt.plot(bin_centers, counts, 'g-o')
plt.title('3. Frequency Polygon (Rainfall)')
plt.xlabel('Rainfall (mm)') # Corrected label
plt.ylabel('Frequency')

# Adding a placeholder for the 4th plot, or adjust layout if only 3 plots are desired
# For now, let's keep 4 slots and leave the 4th empty or add a simple plot
plt.subplot(2, 2, 4) # Added for completeness of 2x2 grid
plt.title('4. Placeholder')
plt.axis('off') # Turn off axes for empty plot


plt.tight_layout()
plt.show()

"""**Temperature Celsius**"""

import matplotlib.pyplot as plt
import numpy as np


temp_data = df_full['Temperature_Celsius']

plt.figure(figsize=(12, 8))


plt.subplot(2, 2, 1)
plt.hist(temp_data, bins=20, color='lightblue', edgecolor='black')
plt.title('1. Histogram')
plt.xlabel('Temperature (°C)')
plt.ylabel('Frequency')

plt.subplot(2, 2, 2)
sorted_data = np.sort(temp_data)
cumulative = np.arange(1, len(sorted_data) + 1)
plt.plot(sorted_data, cumulative, 'r-')
plt.title('2. Ogive Chart')
plt.xlabel('Temperature (°C)')
plt.ylabel('Cumulative Frequency')


plt.subplot(2, 2, 3)
counts, bin_edges = np.histogram(temp_data, bins=20)
bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2
plt.plot(bin_centers, counts, 'g-o')
plt.title('3. Frequency Polygon')
plt.xlabel('Temperature (°C)')
plt.ylabel('Frequency')


plt.subplot(2, 2, 4)
more_than = np.arange(len(sorted_data), 0, -1)
plt.plot(sorted_data, more_than, 'b-')
plt.title('4. More than Ogive')
plt.xlabel('Temperature (°C)')
plt.ylabel('Cumulative Frequency')

plt.tight_layout()
plt.show()

"""**Days to Harvest**"""

import matplotlib.pyplot as plt
import numpy as np


temp_data = df_full['Days_to_Harvest'] # Data is 'Days_to_Harvest'

plt.figure(figsize=(12, 8))


plt.subplot(2, 2, 1)
plt.hist(temp_data, bins=20, color='lightblue', edgecolor='black')
plt.title('1. Histogram')
plt.xlabel('Days to Harvest') # Corrected xlabel
plt.ylabel('Frequency')

plt.subplot(2, 2, 2)
sorted_data = np.sort(temp_data)
cumulative = np.arange(1, len(sorted_data) + 1)
plt.plot(sorted_data, cumulative, 'r-')
plt.title('2. Ogive Chart')
plt.xlabel('Days to Harvest') # Corrected xlabel
plt.ylabel('Cumulative Frequency')


plt.subplot(2, 2, 3)
counts, bin_edges = np.histogram(temp_data, bins=20)
bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2
plt.plot(bin_centers, counts, 'g-o')
plt.title('3. Frequency Polygon')
plt.xlabel('Days to Harvest') # Corrected xlabel
plt.ylabel('Frequency')


plt.subplot(2, 2, 4)
more_than = np.arange(len(sorted_data), 0, -1)
plt.plot(sorted_data, more_than, 'b-')
plt.title('4. More than Ogive')
plt.xlabel('Days to Harvest') # Corrected xlabel
plt.ylabel('Cumulative Frequency')

plt.tight_layout()
plt.show()

"""**Analysis and Conclusion**"""

print ("""Frequency Table Insights

• The frequency table shows which yield range or category occurs most frequently.

• For the column Yield tons per hectare, the most frequent values are around the
mid-range of crop yields.

• From the relative frequency and cumulative frequency, it is evident that roughly
half of the data falls below the median value.



Bar Chart (Regional Analysis)

• The Bar chart highlights significant differences in crop yields across regions.

• West and South regions tend to have higher yields.

• North region shows comparatively lower productivity.

Ogive Charts (Cumulative Frequency Analysis)

• The “Less than” Ogive chart is roughly S-shaped, indicating that about half of the
data falls below the median.

• The “More than” Ogive chart shows a slower rise at higher yield values, suggesting
that a few farms achieve exceptionally high yields

• Ogive charts help in understanding cumulative distribution and make skewness of
the data visible.



Distribution Shape & Variability

• Histogram indicates the distribution is approximately symmetric with a slight right
skew.

• Some high-yield and low-yield observations may be outliers.

• Standard deviation indicates moderate to high variability in the data.

Conclusion

• Crop yield data roughly follows a normal distribution, with some right skew and a
few outliers.


Probability Sampling Methods Sampling Assignment



• Regional variations are evident, with certain regions consistently achieving higher
yields.



• Frequency table, Bar chart, and Ogive analysis together provide a clear understand-

ing of distribution patterns, cumulative trends, and regional disparities.



• This analysis is useful for agricultural planning and decision-making for targeted

interventions.""")

"""**Challenges**

Region-wise differences
"""

crop_distribution = df.groupby(['Region', 'Crop']).size().reset_index(name='Count')
display(crop_distribution.head())

"""Soil type impact"""

print(""" Group the DataFrame by 'Soil_Type' and 'Crop', then calculate the average 'Yield_tons_per_hectare'\nfor each combination to identify which crops yield best on which soil types.

Reasoning: I will group the DataFrame by 'Soil_Type' and 'Crop' and calculate the mean of\n'Yield_tons_per_hectare' to understand the\naverage yield for each combination, then reset the index and create a pivot table for visualization.""")

soil_crop_yield = df.groupby(['Soil_Type', 'Crop'])['Yield_tons_per_hectare'].mean().reset_index()
display(soil_crop_yield.head())

"""Crop-wise analysis"""

avg_yield_per_crop = df.groupby('Crop')['Yield_tons_per_hectare'].mean().reset_index()
display(avg_yield_per_crop)

environmental_conditions = df.groupby('Crop')[['Rainfall_mm', 'Temperature_Celsius']].agg(['mean', 'std']).reset_index()
environmental_conditions.columns = ['Crop', 'Rainfall_mm_mean', 'Rainfall_mm_std', 'Temperature_Celsius_mean', 'Temperature_Celsius_std']
display(environmental_conditions)

"""Weather impact"""

print("Average Yield by Weather Condition:")
display(df.groupby('Weather_Condition')['Yield_tons_per_hectare'].mean().reset_index())

"""Optimal conditions"""

# Method 1: Simple and direct
df.loc[df.groupby('Crop')['Yield_tons_per_hectare'].idxmax()][['Crop', 'Soil_Type', 'Yield_tons_per_hectare']].sort_values('Crop')

# Method 2: Direct display without column renaming
df.groupby('Crop')[['Rainfall_mm', 'Temperature_Celsius']].agg(['mean', 'std'])

"""Climate diversity"""

pd.qcut(df['Rainfall_mm'], 3, labels=['Low', 'Medium', 'High']).pipe(
    lambda x: df.groupby(x, observed=True)['Yield_tons_per_hectare'].mean() )

# Shortest (if you want both)
print(df[['Rainfall_mm', 'Temperature_Celsius']].corrwith(df['Yield_tons_per_hectare']).round(2))

"""Conclusion:"""

print("""During this milestone, several challenges were encountered while analyzing the Agricul-
ture Crop Yield dataset:

1. Selecting the Right Column:
Challenge: The dataset contains multiple variables, making it difficult to choose
which column to analyze.
Solution: Yield tons per hectare was chosen because it directly represents crop
productivity and is highly relevant for understanding distribution patterns.
2. Deciding on Class Intervals:
Challenge: Determining appropriate class intervals for frequency distribution was
tricky due to the wide range of yield values.
Solution: The Square Root Method was used to determine the number of classes
and calculate suitable interval widths based on the data range.
3. Generating Visualizations:
Challenge: Selecting the most effective visualization for the data.
Solution: Multiple visualizations were created:
• Histogram – to see the distribution of yield values.
• Bar Chart – to compare average yields across regions.
• Frequency Polygon – to show smooth distribution patterns.
• Ogive Chart – to analyze cumulative frequency and percentiles.
4. Data Cleaning and Processing:
Challenge: The dataset contained missing values and potential outliers that could

13

Probability Sampling Methods Sampling Assignment

affect analysis.
Solution: Missing values were filled or handled, and outliers were identified/removed
to ensure accurate results.
Conclusion:
Overcoming these challenges allowed a thorough statistical analysis and creation of clear,

informative visualizations. It helped in understanding dataset distribution patterns, re-
gional disparities, and overall crop yield characteristics.""")

"""**[Milestone 4](https://)**

**Milestone 4 - STA 2101: Measures of Central Tendency and Dispersion**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


import pandas as pd

df = pd.read_csv('/content/crop_yield.csv')
df.head()

"""**Task 1: Measures of Central Tendency**"""

import pandas as pd
# Load your dataset
df = pd.read_csv('crop_yield.csv')
df.head()

"""**Task 1: Measures of Central Tendency**"""

import pandas as pd


df = pd.read_csv('/content/crop_yield.csv')
cols = ['Rainfall_mm', 'Temperature_Celsius', 'Days_to_Harvest', 'Yield_tons_per_hectare']


for col in cols:
    print(f"\n=== {col} ===")
    print(f"Mean   : {df[col].mean():.1f}")
    print(f"Median : {df[col].median():.1f}")
    print(f"Mode   : {df[col].mode().iloc[0]}")

# 4. Quick skewness analysis
print("\n" + "-" * 50)
print("QUICK SKEWNESS ANALYSIS")
print("-" * 50)

for col in cols:
    mean_val = df[col].mean()
    median_val = df[col].median()

    if mean_val > median_val:
        skew = "Right skewed (mean > median)"

    elif mean_val < median_val:
        skew = "Left skewed (mean < median)"

    else:
        skew = "Symmetric (mean ≈ median)"


    print(f"{col}: {skew}")

import pandas as pd

df = pd.read_csv('/content/crop_yield.csv')
cols = ['Rainfall_mm', 'Temperature_Celsius', 'Days_to_Harvest', 'Yield_tons_per_hectare']

for col in cols:
    print(f"\n{col}:")

    # Basic stats
    mean = df[col].mean()
    median = df[col].median()
    mode = df[col].mode().iloc[0]
    var = df[col].var()
    std = df[col].std()

    # Print in simple format
    print(f"  Mean   : {mean:.1f}")
    print(f"  Median : {median:.1f}")
    print(f"  Mode   : {mode}")
    print(f"  Var    : {var:.1f}")
    print(f"  Std Dev: {std:.1f}")

    # Simple insight
    if mean > median:
        print(f"  → Right skewed")
    elif mean < median:
        print(f"  → Left skewed")

"""**Task 2: Measures of Dispersion**"""

import pandas as pd

# Load
df = pd.read_csv('/content/crop_yield.csv')
cols = ['Rainfall_mm', 'Temperature_Celsius']


for col in cols:
    print(f"\n{col}:")
    print(f"  Variance : {df[col].var():.2f}")
    print(f"  Std Dev  : {df[col].std():.2f}")

    # Compare
    if df[col].var() > df[cols[0]].var() and col != cols[0]:
        print("  → More spread than", cols[0])

"""**Task 3: Visualization**"""

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('/content/crop_yield.csv')

for col in ['Rainfall_mm', 'Temperature_Celsius']:
    plt.hist(df[col], bins=15, alpha=0.5)
    plt.axvline(df[col].mean(), color='r')
    plt.axvline(df[col].median(), color='g')
    plt.axvline(df[col].mode().iloc[0], color='y')
    plt.title(col)
    plt.show()

"""**Task 4: Analysis and Conclusion**"""

import pandas as pd

df = pd.read_csv('/content/crop_yield.csv')

print("ANALYSIS:")
print(f"Rainfall mean: {df['Rainfall_mm'].mean():.1f}±{df['Rainfall_mm'].std():.1f}")
print(f"Temp mean: {df['Temperature_Celsius'].mean():.1f}±{df['Temperature_Celsius'].std():.1f}")

print("\nCONCLUSION:")
print("Data shows normal distribution with moderate spread.")